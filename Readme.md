<div align="center">
  <h1 align="center">
    <br />
    <br />
    <img src="img/Hotinho_sem_fundo.png" alt="Hotinho">
  </h1>
</div>

## IntroduÃ§Ã£o ğŸ“–

* Hotinho Ã© um projeto desenvolvido para o processo seletivo de machine learning engineer da Hotmart.

* Ele consiste em um assistente que baseado nos documentos textos que sÃ£o enviados para o mesmo, consegue responder perguntas sobre os demais assuntos presentes no documento enviado.

* Para criaÃ§Ã£o do projeto foi necessÃ¡rio a construÃ§Ã£o de duas APIs, a utilizaÃ§Ã£o de um Vector Database open-source (Qdrant) e a criaÃ§Ã£o de uma interface amigÃ¡vel para usuÃ¡rios, que se comunica com cada uma das APIs.

* Cada uma das APIs criadas possui uma funÃ§Ã£o especÃ­fica dentro da arquitetura do projeto.

    - A primeira API recebe documentos (.txt ou .pdf), processa esses documentos, quebra eles em chunks e transforma os chunks em embeddings, para armazenar no Vector Database open-source usado no projeto, o Qdrant.

    - A segunda API recebe uma pergunta atravÃ©s de uma requisiÃ§Ã£o, processa essa pergunta, transforma ela em um embedding e realiza uma busca atravÃ©s de similaridade do cosseno dos embeddings mais similares que estÃ£o armazenados no nosso Vector Database. Dessa maneira, ela vai enviar para o LLM a pergunta e o contexto necessÃ¡rio, assim o LLM irÃ¡ responder a pergunta com base naquele contexto.

* O modelo de embedding usado no projeto foi o 'text-embedding-ada-002' da OpenAI e o LLM usado foi o 'gpt-3.5-turbo-instruct' tambÃ©m da OpenAI. Com isso jÃ¡ tenha em mente que para rodar o projeto no seu computador serÃ¡ necessÃ¡rio gerar uma api-key no site https://platform.openai.com/api-keys

<div align="center">
  <h1 align="center">
    Arquitetura do Projetoâ›ï¸âš™ï¸
    <br />
    <br />
    <img src="img/arquitetura_hotinho.png" alt="Hotinho">
  </h1>
</div>

* Fica visÃ­vel que cada API tem um determinado papel na arquitetura do projeto, e cada uma delas se conecta com o nossa coleÃ§Ã£o dentro do Vector Database, seja para armazenar os embeddings dos arquivos enviados ou para buscar os embeddings mais similares a uma pergunta enviada.

<div align="center">
  <h1 align="center">
    Interface do HotinhoğŸ”¥ğŸš€
    <br />
    <br />
    <img src="img/interface_hotinho.png" alt="Hotinho">
  </h1>
</div>

## InstruÃ§Ãµes para uso do projeto ğŸ‘¨â€ğŸ’»
Para utilizaÃ§Ã£o do projeto na sua mÃ¡quina serÃ¡ necessÃ¡rio realizar alguns passos:

* O primeiro e mais importante de todos os passos Ã© criar um arquivo nomeado (.env) na raiz do projeto. Com isso, vocÃª irÃ¡ setar importantes variÃ¡veis de ambiente que sÃ£o necessÃ¡rias para definir as portas das aplicaÃ§Ãµes e tambÃ©m a sua api-key da OpenAI. O arquivo deve conter as seguintes informaÃ§Ãµes:
<div align="center">
  <h1 align="center">
    .envğŸ“
    <br />
    <br />
    <img src="img/dotenv.png" alt="Hotinho">
  </h1>
</div>


ConteÃºdo do arquivo .env:
```
  OPENAI_API_KEY="sua_api_key"
  PORT_VECTOR_DATABASE=6333
  PORT_API_DOC=8080
  PORT_API_CHAT=5000
  PORT_INTERFACE=8501
```
* ObservaÃ§Ã£o Importante: Se atente a manter os mesmos nomes e portas das variÃ¡veis de ambiente apresentadas na imagem acima, pois essas nomenclaturas estÃ£o sendo referenciadas dentro dos cÃ³digos do projeto. 

* ApÃ³s a criaÃ§Ã£o do arquivo .env, vocÃª irÃ¡ abrir o terminal do seu computador no diretÃ³rio do projeto e setar o seguinte comando:

```
docker-compose build
```  
Esse comando Ã© o responsÃ¡vel por realizar o build de todas as imagens docker das nossas aplicaÃ§Ãµes, lembrando que esse processo pode demorar alguns minutinhos.
* ApÃ³s rodar o 'docker-compose build', serÃ¡ necessÃ¡rio vocÃª setar mais um comando:
```
docker-compose up
```  
Esse comando Ã© o responsÃ¡vel por criar e instanciar todos os containers das nossas aplicaÃ§Ãµes.

Com isso, teremos tudo pronto para poder testar as nossas APIs e o Vector Database, assim como, testar a nossa interface que conecta toda a arquitetura do projeto em uma aplicaÃ§Ã£o amigÃ¡vel para usuÃ¡rios.

```
Qdrant -> http://localhost:6333/dashboard
api_doc -> http://localhost:8080/document
api_chat -> http://localhost:5000/question
interface_Hotinho -> http://localhost:8501
```  
Aqui estÃ¡ os endereÃ§os e endpoints que vocÃª irÃ¡ visualizar no seu browser (como no caso do Qdrant e da aplicaÃ§Ã£o de interface do Hotinho) ou os endereÃ§os das API's que vocÃª usarÃ¡ para testar no POSTMAN, caso prefira!
## Testes e ReprodutibilidadeğŸ§ª
Sobre testes e documentaÃ§Ã£o das API's, abaixo segue um link onde Ã© possÃ­vel visualizar como fazer as requisiÃ§Ãµes e reproduzi-las dentro do POSTMAN ou em outro software de sua preferÃªncia.

Click no link abaixo!

https://documenter.getpostman.com/view/22340062/2sA3XWdepf
<div align="center">
  <h1 align="center">
    DocumentaÃ§Ã£o e Exemplos das API'sğŸ“
    <br />
    <br />
    <img src="img/postman.png" alt="Hotinho">
  </h1>
</div>



## Melhorias futurasğŸ”¥ğŸš€
* Embora o projeto seja uma abordagem poderosa, tem algumas limitaÃ§Ãµes. Uma dessas limitaÃ§Ãµes Ã© a incapacidade de preservar o histÃ³rico da conversaÃ§Ã£o. Cada pergunta Ã© tratada de forma independente e o modelo nÃ£o tem acesso a perguntas ou respostas anteriores. Mas isso Ã© algo possÃ­vel de melhorar dentro do projeto;

* Outra melhoria interessante Ã© dar ao usuÃ¡rio a possibilidade dele criar novas collections dentro do nosso Vector Database. Pois, no projeto atual ele adiciona todos os embeddings dentro de uma mesma collection chamada 'documentos_collection'. PorÃ©m, podemos fazer com que as API's tenham mais endpoints, construindo endpoints de criaÃ§Ã£o e deleÃ§Ã£o de collections, assim, montando diversas bases de conhecimentos diferentes e especÃ­ficas para determinados temas;

* Dar a possibilidade do cliente escolher quais os modelos ele quer que sejam usados no processo de resposta. No projeto estamos usando soluÃ§Ãµes da OpenAI ('gpt-3.5-turbo-instruct'), entÃ£o daria pra fazer com que as API's recebessem nas requisiÃ§Ãµes qual o modelo selecionado (GPT-4 Turbo, GPT-4o, ....) pelos usuÃ¡rios e usar essa informaÃ§Ã£o dentro do cÃ³digo;

* Criar template de prompts mais eficazes do que sÃ³ passar a pergunta para o LLM, fazendo com que a interpretaÃ§Ã£o e a resposta sejam cada vez mais assertivas;

* Por fim, seria interessante tambÃ©m a utilizaÃ§Ã£o de algum mÃ©todo adequado e eficaz de avaliaÃ§Ã£o da nossa RAG, fazendo com que se tenha um ciclo de interaÃ§Ã£o, feedback e adaptaÃ§Ã£o.
