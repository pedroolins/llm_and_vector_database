{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Qdrant\n",
    "## importando o client\n",
    "from qdrant_client import QdrantClient\n",
    "## importando módulos que ajudam a criar nossa coleção\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "##langchain\n",
    "## importando o Qdrant como vector store\n",
    "# from langchain.vectorstores import Qdrant\n",
    "from langchain_qdrant import Qdrant\n",
    "## importando o OpenAi embeddings\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "## Importando função que auxilia na quebra de textos em chunks\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "## importando o módulo que facilita o uso de vector stores em QA(question answering)\n",
    "from langchain.chains import RetrievalQA\n",
    "## importando a llm\n",
    "from langchain_openai import OpenAI\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## carregando as variaveis de ambiente\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## instanciando nosso client do Qdrant\n",
    "client = QdrantClient(host=\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A collection já existe!\n"
     ]
    }
   ],
   "source": [
    "## usando o client para verificar se a collection já existe, caso contrário ele irá criar uma\n",
    "collection_exists = client.collection_exists(collection_name=\"documentos_collection\")\n",
    "if collection_exists:\n",
    "    print(\"A collection já existe!\")\n",
    "else:\n",
    "    ## agora vamos criar a nossa coleção\n",
    "    client.create_collection(\n",
    "        collection_name=\"documentos_collection\",\n",
    "        vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vamos instanciar o OpenAiEmbeddings() lembrado que já temos a nossa variável de ambiente com a chave de api na nomenclatura padrão\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=\"documentos_collection\",\n",
    "    embeddings=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ee0f7ee0312d4ee5b60c4d4198afbd86',\n",
       " '4f072a47dd0e4278bd37f5bfad204fb9',\n",
       " '59702d90948b44ebb7db144275d5738d',\n",
       " 'c5e0a78c88eb4fa69b78d0c3bc0b486c',\n",
       " '21e9f8f2b81e44c299e9eddb8a0665a2',\n",
       " '3c8860e049a1434ba3a62ea37c1630bb',\n",
       " 'fa8abcdd7e9a4f429fb8c6dfb2ea73b9',\n",
       " 'ee482d20103c4e8abbeaa46a260883a5',\n",
       " 'e1ec945f3fc8439492493cc81a643798',\n",
       " '7a39fc2207d548f78a238e0e32529857',\n",
       " 'd14c17b926164dc2b3c932bfd2e07310',\n",
       " '9bf28fa0eac44e5881eea8fa6066dda4',\n",
       " 'e79cb12dfdbb42788dde0a771f2cc07e',\n",
       " '0795396c8b1f4e89a64e95963636e3fb',\n",
       " '5ddebb7ad6c745f3990af90b284be2d2',\n",
       " 'e7858f9ece014610b81803cbbbfd21ca',\n",
       " '508dde3003d84ca58e3e29f1a51883b9',\n",
       " 'dae97076a0ce4d2b8364eea397f302ef',\n",
       " 'dee0bbd52d2144a6bd3abf0149c60c98',\n",
       " '9aa9d9afcbfd4ca393841d1f81f01c9c',\n",
       " '8af29c0dc82445fbae364351f9461329',\n",
       " 'ec1b9d04b4cd43198d1d48c9e2ddc2dc',\n",
       " 'b77537f2cae44c6faf1207b725bd411e',\n",
       " '14747b16f9c84807b086629dbdcf3854',\n",
       " '549899c63fbe411fb8cb8904d3052918',\n",
       " '9ed18260260047fe8a23ffbfcf92af69',\n",
       " 'bfa35b1ecab241ea98a47f940aadac14',\n",
       " '44592a183e51427ca5cbe6d3af255c80',\n",
       " '31e30d6b8ca648688c765a731a1ca0df',\n",
       " '81fb41119da140eaafa35b096b01299e',\n",
       " '76806ec5d9584bcc9dce9072be20b1dd',\n",
       " 'f194f76e30be4ec79c4b6b3bc07b1518',\n",
       " '9eb1c70e403e4815b9119c47b2850274',\n",
       " '0278d3f476b4412ca91f19eec0ae5a3f',\n",
       " 'ce920a303e2947b6ab6514f978314b27',\n",
       " 'e7a64a68a03d489c8b4ed7dcfd5ad407',\n",
       " 'f61e2f86968b4e699713a137eb324754',\n",
       " '38e43eabd1ce4d6ab75c5e41a30020c0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### criando a função que quebra nosso arquivo de texto em chunks\n",
    "def get_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len,\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "## abrindo e lendo o nosso arquivo\n",
    "with open(\"../data/base_dados.txt\") as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "texts = get_chunks(text=raw_text)\n",
    "vector_store.add_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### montando a arquitetura de recebimento da pergunta, transformação em embedding, busca por similaridade no nosso vector database\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vector_store = Qdrant(\n",
    "    client=client,\n",
    "    collection_name=\"documentos_collection\",\n",
    "    embeddings=embeddings\n",
    ")\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=OpenAI(),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"como funciona as comissões da hotmart?\"\n",
    "response = qa.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " As comissões da Hotmart funcionam como uma taxa por venda realizada, sendo que a plataforma recebe uma porcentagem do preço do produto e um valor fixo por venda. A taxa pode variar dependendo do preço do produto e da moeda em que a venda foi realizada, e é paga somente quando uma venda é concretizada.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(response.get(\"result\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
